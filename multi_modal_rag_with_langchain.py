# -*- coding: utf-8 -*-
"""Multi-modal RAG with LangChain.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iLdK2lQ19t5hPDW8OTD7jbAGjfCSZd8C

# Multi-modal RAG with LangChain

## SetUp

Install the dependencies you need to run the notebook.
"""

# for linux
#%suI7do apt-get install poppler-utils tesseract-ocr libmagic-dev

# for mac
# %brew install poppler tesseract libmagic

# Commented out IPython magic to ensure Python compatibility.
# %pip install -Uq "unstructured[all-docs]" pillow lxml pillow
# %pip install -Uq chromadb tiktoken
# %pip install -Uq langchain langchain-community langchain-openai langchain-groq
# %pip install -Uq python_dotenv
!pip install pdfplumber
# %pip install -Uq langchain-groq langchain_huggingface
!pip install ragas[critique] datasets
!pip install -U langchain-pinecone

import os

# keys for the services we will use
os.environ["OPENAI_API_KEY"]="-----"
os.environ["GROQ_API_KEY"] = "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"
os.environ["LANGCHAIN_API_KEY"] = "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"
os.environ["LANGCHAIN_TRACING_V2"] = "true"
os.environ["PINECONE_API_KEY"] = "pcsk_2wZScE_zP5hG6kdQWfDA6jg7FLSZGFYf6VLPeaAF8mXrX3zGJPUx9rEkTVVSCX9T8w8Tg"
os.environ["PINECONE_ENVIRONMENT"] = "us-west1-gcp"  # e.g., "us-west1-gcp"

"""## Extract the data
xtract the elements of the PDF that we will be able t use in the retrieval process. These elements can be: Text, Images, Tables, etc.

### Partition PDF tables, text
"""

import pdfplumber
texts=[]
tables=[]
# Open the PDF and extract pages
with pdfplumber.open('/content/Sample HI Policy.pdf') as pdf:
    for page in pdf.pages:
        texts.append(page.extract_text())
        # print(text) # Extract plain text
        if page.extract_tables():
          tables.append(page.extract_tables())
          # Extract tables

"""## Summarize the data

Create a summary of each element extracted from the PDF. This summary will be vectorized and used in the retrieval process.

### Text and Table summaries

We don't need a multimodal model to generate the summaries of the tables and the text. I will use open source models available on Groq.
"""

from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser

prompt_text = """
You are an assistant tasked with summarizing tables and text.
Give a concise summary of the table or text that perfectly describes the table in starting 2 sentences.

Respond only with the summary, no additionnal comment.
Do not start your message by saying "Here is a summary" or anything like that.
Just give the summary as it is.

Table or text chunk: {element}
"""
prompt = ChatPromptTemplate.from_template(prompt_text)

#
# Summary chain
model = ChatGroq(temperature=0, model="llama-3.1-8b-instant")
summarize_chain = {"element": lambda x: x} | prompt | model | StrOutputParser()

# Summarize extracted text
text_summaries = []
if texts:
    text_summaries = summarize_chain.batch(texts, {"max_concurrency": 5})

# Summarize extracted tables
tables_html = [str(table) for table in tables]  # Convert tables to string format
table_summaries = []
if tables_html:
    table_summaries = summarize_chain.batch(tables_html, {"max_concurrency": 5})

table_summaries[1]



"""## Load data and summaries to vectorstore

### Create the vectorstore (For even better embedding performance at a cost of compute)
"""

import uuid
from langchain.vectorstores import Chroma
from langchain.storage import InMemoryStore
from langchain.schema.document import Document
from langchain.embeddings import OpenAIEmbeddings
from langchain.retrievers.multi_vector import MultiVectorRetriever
from langchain_huggingface import HuggingFaceEmbeddings

model_name = "Linq-AI-Research/Linq-Embed-Mistral"
model_kwargs = {'device': 'cuda:0'}
encode_kwargs = {'normalize_embeddings': False}
hf = HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs
)
# index= pc.Index("gaido-rag")
# The vectorstore to use to index the child chunks
# vectorstore = Chroma(collection_name="multi_modal_rag", embedding_function=hf)

# The storage layer for the parent documents
store = InMemoryStore()
id_key = "doc_id"

from pinecone import Pinecone, ServerlessSpec

pc = Pinecone(api_key="pcsk_2wZScE_zP5hG6kdQWfDA6jg7FLSZGFYf6VLPeaAF8mXrX3zGJPUx9rEkTVVSCX9T8w8Tg")

index_name = "gaido-rag"



from langchain_pinecone import Pinecone

text_field = "text"
cloud = os.environ.get('PINECONE_CLOUD') or 'aws'
region = os.environ.get('PINECONE_REGION') or 'us-east-1'

spec = ServerlessSpec(cloud=cloud, region=region)
# check if index already exists (it shouldn't if this is first time)
if index_name not in pc.list_indexes().names():
    # if does not exist, create index
    pc.create_index(
        index_name,
        dimension=4096,  # dimensionality of text-embedding-ada-002
        metric='cosine',
        spec=spec
    )
# switch back to normal index for langchain
index = pc.Index(index_name)

vectorstore = Pinecone(
    index, hf, text_field
)

"""### Create the vectorstore (For Retrieval)"""

import uuid
from langchain.vectorstores import Chroma
from langchain.storage import InMemoryStore
from langchain.schema.document import Document
from langchain.embeddings import OpenAIEmbeddings
from langchain.retrievers.multi_vector import MultiVectorRetriever
from langchain_huggingface import HuggingFaceEmbeddings

model_name = "intfloat/multilingual-e5-large-instruct"
model_kwargs = {'device': 'cuda:0'}
encode_kwargs = {'normalize_embeddings': False}
hf = HuggingFaceEmbeddings(
    model_name=model_name,
    model_kwargs=model_kwargs,
    encode_kwargs=encode_kwargs
)
# index= pc.Index("gaido-rag")
# The vectorstore to use to index the child chunks
# vectorstore = Chroma(collection_name="multi_modal_rag", embedding_function=hf)

# The storage layer for the parent documents
store = InMemoryStore()
id_key = "doc_id"

from pinecone import Pinecone, ServerlessSpec

pc = Pinecone(api_key="pcsk_2wZScE_zP5hG6kdQWfDA6jg7FLSZGFYf6VLPeaAF8mXrX3zGJPUx9rEkTVVSCX9T8w8Tg")

index_name = "gaido-rag2"



from langchain_pinecone import Pinecone

text_field = "text"
cloud = os.environ.get('PINECONE_CLOUD') or 'aws'
region = os.environ.get('PINECONE_REGION') or 'us-east-1'

spec = ServerlessSpec(cloud=cloud, region=region)
# check if index already exists (it shouldn't if this is first time)
if index_name not in pc.list_indexes().names():
    # if does not exist, create index
    pc.create_index(
        index_name,
        dimension=1024,  # dimensionality of text-embedding-ada-002
        metric='cosine',
        spec=spec
    )
# switch back to normal index for langchain
index = pc.Index(index_name)

vectorstore = Pinecone(
    index, hf, text_field
)

# The retriever (empty to start)
retriever = MultiVectorRetriever(
    vectorstore=vectorstore,
    docstore=store,
    id_key=id_key,
)

"""### Load the summaries and link the to the original data"""

# Add texts
doc_ids = [str(uuid.uuid4()) for _ in texts]
summary_texts = [
    Document(page_content=summary, metadata={id_key: doc_ids[i]}) for i, summary in enumerate(text_summaries)
]
retriever.vectorstore.add_documents(summary_texts)
retriever.docstore.mset(list(zip(doc_ids, texts)))

# Add tables
table_ids = [str(uuid.uuid4()) for _ in tables]
summary_tables = [
    Document(page_content=summary, metadata={id_key: table_ids[i]}) for i, summary in enumerate(table_summaries)
]
retriever.vectorstore.add_documents(summary_tables)
retriever.docstore.mset(list(zip(table_ids, tables)))

print(summary_tables[1])
print(tables[1])

"""### Check retrieval"""

# Retrieve
docs = retriever.invoke(
    "What is the policy start and expire date?? "
)
for doc in docs:

    print(str(doc) + "\n\n" + "-" * 80)

"""## RAG pipeline"""

from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langchain_core.messages import SystemMessage, HumanMessage
from langchain_openai import ChatOpenAI
from base64 import b64decode


def parse_docs(docs):
    """Split base64-encoded images and texts"""
    b64 = []
    text = []
    for doc in docs:
        try:
            b64decode(doc)
            b64.append(doc)
        except Exception as e:
            text.append(doc)
    return {"images": b64, "texts": text}


def build_prompt(kwargs):
    docs_by_type = kwargs["context"]
    user_question = kwargs["question"]

    # Extract text context
    context_text = ""
    if docs_by_type.get("texts"):
        for text_element in docs_by_type["texts"]:
            if isinstance(text_element, list):
                # Flatten nested lists before joining
                flat_text = " ".join(
                    " ".join(map(str, sub_element)) if isinstance(sub_element, list) else str(sub_element)
                    for sub_element in text_element
                )
                context_text += flat_text + "\n"
            else:
                context_text += str(text_element) + "\n"

    # Extract table context
    context_tables = ""
    if docs_by_type.get("tables"):
        for table in docs_by_type["tables"]:
            table_str = "\n".join([" | ".join(map(str, row)) for row in table])  # Convert table rows to strings
            context_tables += f"\nTable:\n{table_str}\n"

    # Construct prompt with context (including tables)
    prompt_template = f"""
    Answer the question based only on the following context only Ground Truth Final Answer, which includes text and tables.
    If you don't know the answer, just say that you don't know, don't try to make up an answer.
    Be specific

    Context:
    {context_text}

    {context_tables}

    Question: {user_question}
    """

    prompt_content = [{"type": "text", "text": prompt_template}]

    # If images are provided, include them
    # if docs_by_type.get("images"):
    #     for image in docs_by_type["images"]:
    #         prompt_content.append(
    #             {
    #                 "type": "image_url",
    #                 "image_url": {"url": f"data:image/jpeg;base64,{image}"},
    #             }
    #         )

    return ChatPromptTemplate.from_messages(
        [
            HumanMessage(content=prompt_content),
        ]
    )


chain = (
    {
        "context": retriever | RunnableLambda(parse_docs),
        "question": RunnablePassthrough(),
    }
    | RunnableLambda(build_prompt)
    | ChatGroq(model="llama-3.3-70b-versatile")
    | StrOutputParser()
)

chain_with_sources = {
    "context": retriever | RunnableLambda(parse_docs),
    "question": RunnablePassthrough(),
} | RunnablePassthrough().assign(
    response=(
        RunnableLambda(build_prompt)
        | ChatGroq(model="llama-3.3-70b-versatile")
        | StrOutputParser()
    )
)

response = chain.invoke(
    "What is the policy commencement date?"


)

print(response)

response = chain_with_sources.invoke(
    " What is the policy commencement date?"
)

print("Response:", response['response'])

print("\n\nContext:")
for text in response['context']['texts']:
    print(text)
    # print("Page number: ", text.metadata.page_number)
    print("\n" + "-"*50 + "\n")
# for image in response['context']['images']:
#     display_base64_image(image)

queries = [
    "What is the name of the insurance product?",
    "What is the policy number mentioned in the document?",
    "What is the sum insured for the policyholder?",
    "What is the policyholder's address?",
    "When does the policy start and expire?",
    "What is the plan type chosen (Individual or Family Floater)?",
    "What is the premium amount for the policy?",
    "What taxes are applicable on the premium?",
    "Is a personal accident cover included in the policy?",
    "What are the coverage options for sum insured in this policy?",
    "Does this policy cover pre-hospitalization expenses?",
    "Does this policy cover post-hospitalization expenses?",
    "Is air ambulance service covered under this policy?",
    "What is the coverage for alternative treatments like Ayurveda or Homeopathy?",
    "What is the maximum limit for robotic surgery under modern treatments?",
    "Does this policy include home care treatment?",
    "Is domiciliary hospitalization covered?",
    "Is a second medical opinion service included in this policy?",
    "How many days of hospitalization are required for inpatient care to be covered?",
    "What is the cash benefit for shared accommodation?",
    "What are the general exclusions in this policy?",
    "Is cosmetic surgery covered under the policy?",
    "Are treatments for obesity and weight control covered?",
    "Does this policy cover maternity expenses?",
    "Is dental treatment covered under this policy?",
    "Are sexually transmitted diseases covered?",
    "What is the waiting period for pre-existing diseases?",
    "Are self-inflicted injuries covered?",
    "What is the exclusion policy for hazardous sports activities?",
    "Are treatments taken outside India covered?",
    "What is the turnaround time for cashless claim approval?",
    "How many days does it take to resolve a grievance?",
    "What is the claim submission deadline for reimbursement?",
    "What documents are required for claim submission?",
    "Where can the insured check the list of network hospitals?",
    "How can an insured person track their claim status?",
    "Is there a dedicated helpline for claim support?",
    "What is the process for availing of cashless hospitalization?",
    "Is there a list of unrecognized hospitals in the document?",
    "Can a claim be rejected if treatment is taken at an unrecognized hospital?",
    "What is the booster benefit in this policy?",
    "How does the live healthy discount work?",
    "What is the maximum increase in sum insured due to booster benefits?",
    "Is there any renewal premium discount based on health metrics?",
    "What is the safeguard+ feature in this policy?",
    "Is there an option for room type modification under this policy?",
    "Does the policy provide benefits for a health check-up?",
    "Is there an annual aggregate deductible mentioned in the policy?",
    "How does the sum insured safeguard feature work?",
    "Can the sum insured be changed during renewal?"
]

ground_truths = [
    "ReAssure",
    "33033225202502",
    "INR 26,37,750",
    "1-59 NARSIMHA SAGAR MULUGU TELANGANA, 506172, WARANGAL, TELANGANA - 506172",
    "Start: 17/02/2025 00:00 Expire: 16/02/2026 23:59",
    "Individual",
    "INR 12824.00",
    "The premium in this context is subject to Integrated Goods and Service Tax (IGST) at a rate of 18%. The tax amount is calculated as follows: Gross Premium (Rs. 12,824.00) * IGST Rate (18%) = Rs. 1,956.24.",
    "No",
    "Sum Insured Options are: 3 Lacs, 4 Lacs, 5 Lacs, 7.5 Lacs, 10 Lacs, 12.5 Lacs, 15 Lacs, 20 Lacs, 25 Lacs, 50 Lacs, 75 Lacs, 100 Lacs",
    "Yes, for 60 days",
    "Yes, for 180 days",
    "Yes",
    "Upto Sum Assured",
    "The maximum limit for robotic surgeries under 'Modern treatments' is Rs. 1 Lac, except for Robotic total radical prostatectomy, Robotic cardiac surgeries, Robotic partial nephrectomy, and Robotic surgeries for malignancies. These specific procedures do not have a limit.",
    "Yes",
    "Yes",
    "Once for any condition for which hospitalization is triggered",
    "Minimum period of 24 hours",
    "Rs. 800 per day; maximum Rs. 4,800",
    "Detailed exclusion in section 6.",
    "No, cosmetic surgery is not covered under the given policy",
    "Yes, partially covered under certain conditions",
    "Yes, with specific exclusions and waiting period",
    "No, dental treatment is not explicitly covered",
    "Yes, sexually transmitted diseases (excluding HIV/AIDS) are covered",
    "36 months",
    "No, self-inflicted injuries are not covered",
    "Excludes professional participation in hazardous/adventurous sports",
    "No",
    "Pre-authorization: 1 hour; Final authorization: within 3 hours",
    "14 Days",
    "Within 48 hours of admission or before discharge, whichever earlier",
    "Claim form, medical history, identity proof, photo, discharge certificate, banking details",
    "Official website nivabupa.com",
    "User can track their claim status on website",
    "Yes, dedicated helpline: 1860-500-8888",
    "Detailed cashless hospitalization process provided",
    "Yes",
    "Yes",
    "Cumulative bonus increases sum insured by 50%, conditions apply",
    "Discount on renewal premium based on accumulated health points",
    "Maximum increase up to 100% of Base Sum Insured",
    "Yes, renewal discount based on health points accumulated via mobile app",
    "Safeguard+ includes Claim Safeguard, Booster Benefit Safeguard, and CPI-linked Sum Insured increase",
    "Yes, with medical expenses pro-rated",
    "Yes, only on a cashless basis for diagnostic tests",
    "No",
    "CPI-linked increase in Base Sum Insured, sequence for utilization specified",
    "Yes, subject to underwriting at renewal"
]

results = []
contexts = []

for query in queries:
    response = chain_with_sources.invoke(query)

    # Append the generated answer
    results.append(response['response'])

    # Extract and store all source document texts for the current query
    context_texts = response['context']['texts']
    contexts.append(context_texts)

# Example to print results and contexts for verification
for i, query in enumerate(queries):
    print(f"\nQuery: {query}")
    print(f"Response: {results[i]}")
    print("Context:")
    for text in contexts[i]:
        print(text)
        print("\n" + "-"*50 + "\n")

from ragas import evaluate
from datasets import Dataset
# from ragas.metrics.critique import harmfulness
from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall, context_entity_recall, answer_similarity, answer_correctness
import pandas

from ragas import evaluate
from datasets import Dataset
from ragas.metrics import faithfulness, answer_relevancy, context_precision, context_recall, context_entity_recall, answer_similarity, answer_correctness
import pandas as pd

# Correcting the format of contexts to be a list of strings
d = {
    "question": queries,
    "answer": results,
    "contexts": [ [str(item) for item in context_list] for context_list in contexts ],  # contexts as list of strings
    "ground_truth": ground_truths
}

dataset = Dataset.from_dict(d)

# Evaluate using RAGAS metrics
score = evaluate(
    dataset,
    metrics=[
        faithfulness, answer_relevancy, context_precision,
        context_recall, context_entity_recall, answer_similarity,
        answer_correctness
    ]
)

# Convert scores to pandas DataFrame and save to CSV
score_df = score.to_pandas()
score_df.to_csv("EvaluationScores.csv", encoding="utf-8", index=False)

# Display scores for verification
# print(score_df[1])

score_df[['semantic_similarity']].mean(axis=0)

score_df[['faithfulness','answer_relevancy', 'context_precision', 'context_recall',
       'context_entity_recall', 'semantic_similarity', 'answer_correctness',]].mean(axis=0)